{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**October 13, 2020**\n",
    "\n",
    "**1:00-1:40**\n",
    "## Optimized Python for Working with Data and API's\n",
    "_Dolsy Smith_\n",
    "\n",
    "_George Washington University_\n",
    "\n",
    "dsmith@gwu.edu\n",
    "\n",
    "Thanks to Alma’s API’s, we can create custom applications, automate workflows, and perform batch operations not possible with Jobs and Sets. However, using the API’s on large amounts of data can be slow. In this session, we will explore tools and strategies available in Python that can make these tasks and applications more efficient. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "#### Why I Use Python\n",
    "\n",
    "- It's a scripting language with user-friendly syntax, making it relatively easy to learn.\n",
    "- It's a high-level language with some great features (like list comprehensions) that make it useful for rapid prototyping. \n",
    "- It has a huge open-source ecosystem, with third-party Python libraries available for almost every task you might imagine.\n",
    "- For an interpreted language, it's fairly performant.\n",
    "\n",
    "#### Why \"Optimized\" Python?\n",
    "\n",
    "Being interpreted, native Python cannot achieve the efficiency of compiled languages like Java and C. Several robust approaches exist to mitigate this limitation:\n",
    "\n",
    "  - Use high-performance libraries that delegate repetitive operations to a lower-level language under the hood.\n",
    "  - Invoke multiple threads and/or processors.\n",
    "  - Take advantage of Python's support for asynchronous/concurrent I/O.\n",
    " \n",
    "We will look at the first and third of these approaches today.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Cases\n",
    "\n",
    "The following are a handful of ways I've used these approaches in my work with Alma and its API's.\n",
    "\n",
    "##### Discharging over 60,000 items using Alma's scan-In API. \n",
    "\n",
    "With concurrent requests, this took a [Python script](https://github.com/gwu-libraries/bulk-loans-discharge-alma)  roughly 45 minutes to complete on my laptop.\n",
    "\n",
    "\n",
    "##### Looking up Alma users in real-time for a LibCal integration. \n",
    "\n",
    "Needing to adhere to strict constraints on usage of our library's physical spaces during the pandemic, we require patrons to book an appointment in LibCal. [Our application](https://github.com/gwu-libraries/libcal_pp_integration) retrieves appointments from the LibCal API, enriches them with user data from Alma, and loads them into our visitor-management software. Concurrent requests allow us to retrieve data for multiple users from Alma at the same time -- an important piece of efficiency, since our app is fetching appointments at 5-minute intervals.\n",
    "\n",
    "\n",
    "##### Testing legacy portfolio URL's\n",
    "\n",
    "After migration, we found ourselves with several thousand portfolios that had been created from Voyager catalog records (as opposed to the activations from our ERM). Being unattached to collections, these would have to be analyzed one by one. But with concurrent requests, I was able to test the URLs quickly and identify those that did not return a valid HTTP response so that they could be deactivated.\n",
    "\n",
    "\n",
    "##### Migration cleanup: merging and munging\n",
    "\n",
    "After our migration, we had (and still have) lots of cleanup to do. Frequently, this involves comparing Alma Analytics reports with data from other sources, including our legacy Voyager database. With Python's `pandas` module, I can  filter, clean, re-shape, and merge large datasets far more efficiently than in Excel. Plus, `pandas` supports a variety of input and output formats, including `.csv` and `.xlsx` files. Doing this work in Jupyter notebooks has the further advantage of allowing me to document my process in Markdown, which makes the work more shareable and reproducible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This workshop presents an optimized workflow for batch operations using Python and the Alma API's. \n",
    "\n",
    "#### Outline\n",
    "1. API housekeeping (YAML)\n",
    "2. Reading an Analytics report in Python (`pandas`)\n",
    "3. A brief primer on asynchronous programming\n",
    "4. Making API requests asynchronously (`aiohttp`)\n",
    "5. Processing the results (`pandas`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup with `pandas` and YAML\n",
    "\n",
    "#### YAML files for configuration\n",
    "\n",
    "YAML is \"human-readable data-serialization language\" [Wikipedia](https://en.wikipedia.org/wiki/YAML) that works much like JSON but without all the extra punctuation. Like Python, it uses whitespace/indentation to create nested blocks (instead of JSON's curly braces), and it doesn't require quotation marks around strings except in certain situations.\n",
    "\n",
    "I've stored my API key, the Alma API endpoint I'll be using, and the path to a CSV file containing identifiers in a file called `workshop-config.yml`. The following allows me to read these config values into a Python dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you haven't already, run !pip install pyaml\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./workshop-config.yml', 'r') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_url': 'http://slowwly.robertomurray.co.uk/delay/1000/url/http://www.google.com',\n",
       " 'api_key': 'l8xx77562cda96264fa1afb585e50d992fad',\n",
       " 'get_item_url': 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/{mms_id}/holdings/{holding_id}/items/{item_id}',\n",
       " 'csv_path': './items_technical_migration.csv'}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, I'm leaving this as a global variable. We'll use it throughout the workflow that follows.\n",
    "\n",
    "#### Reading Analytics data with `pandas`\n",
    "\n",
    "The report I'm using contains items that received an error status during our migration to Alma. The report has about 20,000 rows. We'll work with a subset of them for this example. \n",
    "\n",
    "In what follows, I'll walk through some of the features of the `pandas` library that make it useful for cleaning and re-shaping data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we read our report into `pandas`. The report has been saved locally as a CSV.\n",
    "\n",
    "The `.read_csv` method returns a `DataFrame` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "migration_errors = pd.read_csv(config['csv_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column names are the standard Analytics column names, in title case with whitespace. These will be easier to work with if we make them valid Python identifiers. We can do this by way of a list comprehension applied to the `.columns` attribute on our `DataFrame`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "migration_errors.columns = [column.lower().replace(' ', '_') for column in migration_errors.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two columns named `suppressed_from_discovery`. The first is for the holdings record, the second for the bib. We should probably rename them to avoid confusion.\n",
    "\n",
    "The following `for` loop uses built-in Python list functions to create new headers for the `suppressed_from_discovery` columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_names = ['suppressed_holdings', 'suppressed_bibs']\n",
    "new_columns = []\n",
    "for column in migration_errors.columns:\n",
    "    if column == 'suppressed_from_discovery':\n",
    "        new_columns.append(new_names.pop(0))\n",
    "    else:\n",
    "        new_columns.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "migration_errors.columns = new_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's exclude those suppressed items (holdings or bibs) from our set. We can do this using the `.loc` functionality of a `DataFrame`, which can accept a Boolean expression, returning only those rows for which the Boolean expression evaluates to `True`.\n",
    "\n",
    "If you evaluate on its own either one of the expressions in parentheses below, you'll notice that it returns a data structure called a `Series`, which in this case has the same number of rows as the original `migration_errors` `DataFrame`. But for values each `Series` has only `True` and `False`. Passing those expressions to `migration_expressions.loc` (which is not a function, but an indexer, hence the square brackets) gives us the result we want. \n",
    "\n",
    "The pipe symbol `|` is used here in place of the keyword `or` because we are comparing two Boolean values for _every row of the `DataFrame`_, rather than comparing two objects (the Boolean `Series` themselves)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "migration_errors = migration_errors.loc[(migration_errors.suppressed_holdings == 0) | (migration_errors.suppressed_bibs == 'No')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the same process to exclude items in temporary locations.\n",
    "\n",
    "(Here, the value `None` coming from Analytics has been read by Python as a string, not as the Python null type `None`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "migration_errors = migration_errors.loc[migration_errors.temporary_location_name == 'None']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, what if we want to limit our set by call number, only to items in the N's? \n",
    "\n",
    "`pandas` support efficient indexing by string conditions, using the `.str` attribute of a column that consists of Python strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_books = migration_errors.loc[migration_errors.permanent_call_number.str.startswith('N')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could, of course, achieve these same results in Analytics by using filters. But the ability to do so in Python often gives me greater flexibility, since I can quickly try different approaches without re-running the query. In addition, `pandas` has far more tools for data cleanup and analysis than the restricted SQL set of Analytics. Finally, I can use `pandas` to merge Analytics data sets with data from other sources (including other Analytics subject areas). \n",
    "\n",
    "We could easily devote a whole workshop to exploring `pandas`. But for now, we'll see how to use our filtered report to create concurrent requests to the Alma API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asynchronous programming: a brief primer\n",
    "\n",
    "The following section attempts to illustrate some of the principles of asynchronous programming via more atomic Python constructs, namely, iterators, generators, and coroutines. At the end of this notebook, I've provided additional resources on this topic. Depending on your background in writing code, it may not be an easy topic to grasp; I certainly struggled with it for several years before it began to crystallize (before I could really understand why the code I wrote sometimes behaved the way it did). What helped was seeing the connection between the higher-level asynchronous syntax I'll introduce below, and the more foundational parts of the language we'll turn to now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most Python code we write executes in a **synchronous** fashion. But what does _that_ mean? \n",
    "  - It's not necessarily about things happening _at the same time_. \n",
    "  - Rather, it's about things happening _in sync_ with one another. As in synchronized swimming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By definition, a `for` loop in Python executes the statements in the block sequentially. Another way to put it is that the outcome of the loop is deterministic: the variable `i` will take on the values from `range(5)` always in this order. If it somehow printed the `3` before the `2`, we would conclude that something had gone terribly wrong.\n",
    "\n",
    "In fact, strictly speaking, the Python interpreter _never_ does more than one thing at the same time. For complicated reasons, and as conventional wisdom has it, Python isn't very good at parallel processing. There is the  `multiprocessing` library, but it effectively spawns multiple copies of the Python interpreter, which comes with a certain amount of overhead. \n",
    "\n",
    "Libraries like `pandas`, which support fast computation, tend to delegate CPU-intensive operations to lower-level code (usually written in C). But there are other things we use Python for that don't consume a lot of CPU cycles, but which can still slow down our code. Chief among these are operations involving what's called _blocking I/O_. \n",
    "\n",
    "#### Do Python scripts dream of electric sheep?\n",
    "\n",
    "Let's say we need to request data from the same webserver five times in a row. If our requests **block**, then between sending the request and receiving the response, nothing else can happen on our end. It's as though whenever you sent an email, you had to wait until the recipient responded before sending another. That would certainly make your inbox easier to organize, but on the other hand, you might not be able to accomplish much.\n",
    "\n",
    "Using Python's `requests` library, we can see this behavior in action. (Do `!pip install requests` first if you get a `ModuleNotFound` error when running the `import` statement.)\n",
    "\n",
    "The URL we're using for this test causes a delay of at least one second before the server returns a response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sync_fn(i):\n",
    "    resp = requests.get(config['test_url'])\n",
    "    print(f'Loop {i}; URL status: {resp.status_code}; Timestamp: {datetime.now().time()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 0; URL status: 200; Timestamp: 09:15:29.592248\n",
      "Loop 1; URL status: 200; Timestamp: 09:15:30.918724\n",
      "Loop 2; URL status: 200; Timestamp: 09:15:32.451844\n",
      "Loop 3; URL status: 200; Timestamp: 09:15:33.870340\n",
      "Loop 4; URL status: 200; Timestamp: 09:15:35.171670\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    sync_fn(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The timestamps should be roughly one second apart. Most of that time was spent by Python idling for a response. Which is not such a big deal if we're making 5 requests, or even 500, but what about 5,000 or 50,000?\n",
    "\n",
    "The alternative is to write code that doesn't block on certain kinds of I/O. How do we accomplish, if the Python interpreter only does one thing at a time?\n",
    "\n",
    "It might help to think about multitasking. Human beings do many things at the same time, like walking and breathing and digesting food. But when we talk about multitasking, we're usually talking about something short of true simultaneity. Handling email correspondence is a good example: you might be engaged in multiple threads of conversation throughout the day. You might be writing a couple of emails while watching a webinar. But it would be quite the neurological feat if three separate parts of your brain were each working on a different task, completely in parallel. More likely, the same parts of your brain are quickly switching back and forth between the tasks. Multitasking is an exercise in effective sequencing. Consider the case where you compose an email, send it, compose another, send it, send a third, receive a response to the first, reply, compose a fourth email while waiting for replies to the other two, and so on. \n",
    "\n",
    "Such commonplace multitasking is analogous to **non-blocking** I/O. Different languages support non-blocking I/O (if they support it at all) in different ways. In Python 3, the `asyncio` library provides this support. \n",
    "\n",
    "Before we turn to `asyncio`, let's take a closer look at the building blocks of Python's support for asynchronous programming.\n",
    "\n",
    "#### Iterators, generators, and coroutines, oh my!\n",
    "\n",
    "An **iterator** is a special Python object that permits iteration. It does so by producing a sequence of values _on demand_. Some built-in Python functions are iterators. `enumerate`, for example, which accepts a sequence of values and returns, for each element in the sequence, a pair of values: the original element and its index. Normally, we use `enumerate` in a `for` loop, but we can expose its iterator nature by using the `next` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "enum = enumerate(['a', 'b', 'c'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used outside of a loop context, `enumerate` doesn't actually enumerate anything. But running `next(enum)` repeatedly will produce values from the sequence until it is exhausted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 'a')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(enum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `StopIteration` exception will be caught by a Python `for` loop, so normally we don't see it. But it represents the iterator's signal that it has no more values to emit.\n",
    "\n",
    "An easy way to create your own iterator in Python is to write a function that uses the `yield` keyword. Such functions are called **generators**. When the Python interpreter encounters a generator, it turns that function into an iterator object. \n",
    "\n",
    "We could write our own version of `enumerate` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_enumerate(seq):\n",
    "    i = 0\n",
    "    while seq:\n",
    "        yield i, seq.pop(0)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "enum2 = my_enumerate(['a', 'b', 'c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 'a')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(enum2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`my_enumerate` isn't as useful as the built-in `enumerate`; for one, our version works only on Python lists. But the relevant point for our discussion of asynchronous programming is this. A regular Python function (one without the `yield` keyword) is \"one-and-done,\" so speak: it is called from a particular context, it executes its code, and then it returns the control flow to the calling context. A regular Python function demands the interpreter's undivided attention. Or from the user's perspective, calling a regular Python function is a bit like ordering food for curbside pickup: you submit your order, you wait, and then you receive your food. \n",
    "\n",
    "A generator, on the other hand, when called with `next` or used in a `for` loop, behaves more like a server in a sit-down restaurant, bringing your meal one dish at a time. But unlike dine-in service, generators can actually be more efficient than regular functions in many contexts. One reason for this is that generators -- or more precisely, the iterators that they become -- do not need to allocate a set amount of memory in advance. For instance, we can use them to parse a file line by line without reading the whole file into memory first. Or we can create generators capable of producing infinite sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_infinity():\n",
    "    i = 0\n",
    "    while True:\n",
    "        yield i\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "gen = to_infinity()\n",
    "for _ in range(10):\n",
    "    print(next(gen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `to_infinity` function will never raise a `StopIteration` exception. If run for enough iterations, it will consume all the available memory. \n",
    "\n",
    "Thus far we haven't seen any asynchronous behavior, but in the guise of generators, we have met Python functions that can start and stop on demand. We can also write generators that can communicate with their calling context. If you're dining in a restaurant, you generally don't have to order all your food at once. You can order an appetizer while you decide on your entree. The following generator, which is technically called a **coroutine**, we can use like a calculator to perform running sums:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def co_sum():\n",
    "    total = 0\n",
    "    while True:\n",
    "        n = yield total\n",
    "        if not n:\n",
    "            return total\n",
    "        total += n\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the `yield` keyword appears on the right-hand side of an equals sign. The line `n = yield total` instructs the function to provide the value of `total` to the calling context, and then to \"wait\" until it receives a new value from that context. The calling context can provide such a value with the `.send` method (built into every generator by default). I put _wait_ in quotation marks because the key thing about a coroutine is that **while it waits for new input, it doesn't actually block the Python interpreter from doing other tasks.** It just sits there until its `.send` method is called, at which point it resumes execution where it left off, pausing again at **the next `yield` statement**. \n",
    "\n",
    "The only quirk is that we have to \"prime\" the coroutine by calling `.send(None)` before we can use it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc = co_sum()\n",
    "calc.send(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc.send(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc.send(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc.send(14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `co_sum` coroutine will keep adding until it encounters an error (_e.g._, it runs out of memory, or we send it a non-numeric value). We can make it quit gracefully by sending `None`, which returns the current value of `total` inside a `StopIteration` exception. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "25",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-ef535cde3b62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcalc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m: 25"
     ]
    }
   ],
   "source": [
    "calc.send(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coroutines in action: `async`, `await`, and `asyncio`\n",
    "\n",
    "Since version 3.5, Python as provided higher-level abstractions for using coroutines with non-blocking I/O. Again, the use cases here are those where a Python program is waiting on input from an external process, such as the response from a webserver. These abstractions consist of two new keywords -- `async` and `await` -- and a module in the standard library, `asyncio`. \n",
    "\n",
    "`asyncio` provides an implementation of an **event loop**. There are a variety of patterns for using the event loop, but in one of the most straighforward patterns, which we'll employ below, the event loop manages a collection of coroutines, each of which has one task that involves non-blocking I/O. To modify our previous analogy, imagine a server in a busy restaurant. The server is the event loop; their tables are the coroutines. Because diners spend far more time (as a general rule) eating than they do ordering food, the server can manage many tables at once. All they need to do is keep checking with each table to see if they want to order something else (if the coroutine has a value to `yield`). \n",
    "\n",
    "Using `asyncio`, we don't have to write the event loop ourselves. All we have to do is supply it with a collection of coroutines to manage.\n",
    "\n",
    "Our coroutines we define by using the `async` and `await` keywords. \n",
    "\n",
    "Unfortunately, we can just stick `await` in front of every Python function to make it asynchronous. Even Python functions that work with I/O -- like the `requests` library we used above -- cannot be uses asynchronously if they were not designed to be. But there are a growing number of Python libraries for asynchronous I/O. Here we'll use the library called `aiohttp` for making asynchronous HTTP requests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to install `aiohttp` first: `!pip install aiohttp`. \n",
    "\n",
    "Then we import both `aiohttp` and `asyncio`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To define an asynchronous coroutine, use `async def` in place of `def`. And such a coroutine must include at least one `await` statement.\n",
    "\n",
    "Here our coroutine makes a simple HTTP request. The code is a bit more complex because `aiohttp` uses _context managers_ to handle opening and closing HTTP connections. The `async with` statement is an asynchronous version of the regular Python `with` statement that creates an instance of a context manager. \n",
    "\n",
    "Our coroutine also accepts a `client` argument, which will be an object created by the `aiohttp.ClientSession` context manager. This allows us to re-use the same connection for multiple requests.\n",
    "\n",
    "Note that the `yield` keyword does not appear inside our async coroutine. (In Python 3.6+, it's possible to `yield` from an async coroutine, but it's not required.) Here `await` does the work of pausing the coroutine until it receives a value from \"outside,\" as it were. An important difference between `await` and `yield` is that **we** are **not** sending the value (as we did above with `calc.send()`). Rather, the value is coming from the special asynchronous `text()` method on our `aiohttp` object. \n",
    "\n",
    "You can only `await` other async coroutines (and some other specialized Python objects called Futures and Tasks). \n",
    "\n",
    "The `async` keyword in front of the `def` and the `with` keywords is important. Without them, the code will either throw an exception or not work as intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def async_fn(i, client):\n",
    "    async with client.get(config['test_url']) as session:\n",
    "        resp = await session.text()\n",
    "        print(f'Loop {i}; URL status: {session.status}; Timestamp: {datetime.now().time()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, we initialize our collection of coroutines inside another asynchronous function (coroutine). We'll call this one `main`.\n",
    "\n",
    "1. `main` invokes the `aiohttp.ClientSession` context manager, creating an instance of a client that we can re-use across all our requests. \n",
    "2. Then it creates a collection of `async_fn` coroutines, initializing each with a new value between 0 and 4 and with the client created above.\n",
    "3. Next we pass this collection to `asyncio.gather` and `await` it. `gather` will execute the coroutines concurrently, ensuring that their results (if any) are accumulated and arranged according to the order in which they were submitted.\n",
    "\n",
    "The `await` keyword before `asnycio.gather` is important. Our `main` coroutine, like our `async_fn` coroutines, will run _inside_ the event loop. This seems counterintuitive, since `main` manages other coroutines. But it's actually more of a helper; there is a different function that kicks off the event loop itself, which we'll see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    async with aiohttp.ClientSession() as client:\n",
    "        awaitables = [async_fn(i, client) for i in range(5)] # Here async_fn(i, client) doesn't execute -- it only initializes the corouting\n",
    "        await asyncio.gather(*awaitables)  # The asterisk before the variable unpacks the list -- gather() expects one or more coroutines but not a list of them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python 3.7+, we would write -- from some **non** async function or from the main part of our script -- the following to call the `main` coroutine:\n",
    "\n",
    "`asyncio.run(main)`\n",
    "\n",
    "- This **blocking** command populates the event loop with the coroutine `main`. \n",
    "- The `main` coroutine then adds each initialized instance of our `async_fn` coroutine (via the `awaitables` variable) to the event loop. \n",
    "- **Each instance of `async_fn` makes an HTTP request then cedes control back to the event loop.** \n",
    "- **The event loop checks each coroutine to see if it has received a response.**\n",
    "- Once **all** of the `async_fn` coroutines have finished -- either by returning or raising an exception -- the `main` coroutine will return.\n",
    "- At this point, execution will resume after the call to `asyncio.run`. \n",
    "\n",
    "In a Jupyter Notebook, however, we are already inside an event loop. So we can't call `asyncio.run` without getting an error. Fortunately, we can just write `await main()` to get the same behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 0; URL status: 200; Timestamp: 09:16:08.227113\n",
      "Loop 2; URL status: 200; Timestamp: 09:16:08.228655\n",
      "Loop 1; URL status: 200; Timestamp: 09:16:08.229905\n",
      "Loop 4; URL status: 200; Timestamp: 09:16:09.132163\n",
      "Loop 3; URL status: 200; Timestamp: 09:16:09.133798\n"
     ]
    }
   ],
   "source": [
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing this output with our synchronous loop above, notice the following:\n",
    "- The timestamps should be within a few milliseconds of each other, even though each HTTP server still took at least 1 second to respond. The requests were made concurrently, so the **total** time to send the requests and receive the responses should be approximately 1 second.\n",
    "- `asyncio.gather` guarantees that it will **return results** from coroutines in the order that they were passed to it. In this case, however, the output on screen is from a `print` statement inside each coroutine, showing that the coroutines do not necessarily **complete** in the same order. \n",
    "- That's the key to asynchronous programming: it eases the requirement that every operation occur in the sequence stipulated by the programmer. \n",
    "- And in exchange for some loss of synchronicity, we get significant gains in performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Alma API's asynchronously\n",
    "\n",
    "The preceding tour of iterators, generators, and coroutines was intended to provide some conceptual grounding for a grasp of how Python's `async` coroutines work. To summarize, the key points are as follows:\n",
    "\n",
    "1. **Coroutines** are Python functions that can suspend their operation while waiting for more input. While they are paused, the Python interpreter can do other work.\n",
    "2. `async` coroutines, which typically handle input from I/O processes, are managed by the `asyncio` **event loop**. The event loop is responsible for resuming the coroutines based on the availability of their input from external processes (like an HTTP response). \n",
    "3. The event loop allows us to achieve **concurrency** in our I/O requests. This is not the same as true parallelism, but more like highly efficient multitasking. Since the processes involved typically don't require much, if any, of the Python interpreter's resources -- and may not even involve many system resources -- asynchronous programming in Python is essentially a way to **occupy the idle time** that the interpreter would otherwise spend waiting for responses from elsewhere.\n",
    "\n",
    "The **main challenge** in writing asynchronous Python is adapting to a different way of programming, one in which the path from input to output is less straightforward (and in some sense, less predictable)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Alma API's impose a **rate limit** of 25 requests per second. With synchronous approaches, that's typically not a problem, because the API generally doesn't respond quickly enough for us to be able to make 25 requests _in sequence_ in under a second. But _concurrent_ requests are different. We can pass 100, 1,000, or 100,000 `async` coroutines to the event loop, and if each coroutine makes one request, the event loop will issue those requests immediately, the only constraint being how fast the hardware on our end can handle it. As a result, we can easily exceed the rate limit if we don't **throttle** the requests somehow.\n",
    "\n",
    "We'll use a tiny Python library call `asyncio-throttle` to do that, which you can install by running\n",
    "```\n",
    "!pip install asyncio-throttle\n",
    "```\n",
    "in your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from asyncio_throttle import Throttler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing an `async` coroutine to make API requests\n",
    "\n",
    "The following function will make a single GET request. \n",
    "\n",
    "1. The function accepts the following arguments:\n",
    "  - An instance of the `aiohttp.ClientSession` class. This allows us to reuse the same connection across requests.\n",
    "  - An instance of the `Throttler` class from `asyncio_throttle`. \n",
    "  - A url string. The URL in this case will be formatted for retrieving a specific item from the Bibs API.\n",
    "  - A Python dictionary called `headers`. This will contain the header information required by the API.\n",
    "\n",
    "\n",
    "2. The function will return either\n",
    "  - a valid response from the API, which we expect to be in JSON format,\n",
    "  - or an error.\n",
    "  - Both types of return values will be Python dictionaries.\n",
    "\n",
    "\n",
    "3. Error handling with asynchronous programming can be challenging. \n",
    "  - If a coroutine raises an exception, the `asyncio` event loop will allow the rest to continue execution. That's helpful, because in a case like ours, we wouldn't want one API error -- which might be causes by a bad identifier -- to cause the whole batch to fail. \n",
    "  - However, it's important to keep track of which API calls **did** fail and why. In our function, we use `try...except` blocks to catch exceptions, and we package errors in Python dictionaries, including, where possible, the API response, which may include a useful message. \n",
    "\n",
    "\n",
    "4. Note the nested `async with` statements:\n",
    "  - `async with throttler` applies the throttler to our request. This essentially keeps our coroutine in a queue until it's time to be executed (at a rate of no more than 25 per second).\n",
    "  - `async with client.get(...) as session`: This context manager creates a single request session, closing it out when we exit the block. This ensures that we can reuse the same client between requests effectively.\n",
    "\n",
    "\n",
    "5. There are two `await` statements here.\n",
    "  - The first, which is executed in the case of an HTTP error, gets the HHTP response body as a string and assigns it to the `resp` variable.\n",
    "  - The second, executed in the case of a successful HTTP requests, parses the HTTP response body as JSON.\n",
    "  \n",
    "  \n",
    "6. Our function uses the `aiohttp.ClientSession.get` method, but with a couple of tweaks we could make this function handle POST requests instead. \n",
    "  - Replace the above method call with one to `aiohttp.ClientSession.post`.\n",
    "  - Accept as an argument some data to be POST-ed, and include this in the method call as a `data` keyword argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_item(client, throttler, url, headers):\n",
    "    async with throttler:\n",
    "        try:\n",
    "            resp = None\n",
    "            async with client.get(url, headers=headers) as session:\n",
    "                if session.status != 200:\n",
    "                    resp = await session.text()\n",
    "                    session.raise_for_status()\n",
    "                resp = await session.json()\n",
    "                return {'url': url, 'response': resp}\n",
    "        except Exception as e:\n",
    "            return {'error': e, 'message': resp}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the API URL's\n",
    "\n",
    "We used `pandas` to load the identifiers for our API requests from a CSV file. Let's look at how we can extract the data we need from our `DataFrame`.\n",
    "\n",
    "Our API endpoint looks like this:\n",
    "```\n",
    "almaws/v1/bibs/{mms_id}/holdings/{holding_id}/items/{item_id}'\n",
    "```\n",
    "\n",
    "So we will need the MMS, Holdings, and Item ID numbers. \n",
    "\n",
    "- A `DataFrame` has an `.itertuples()` method that is an iterator; it produces a Python [named tuple](https://docs.python.org/3/library/collections.html#collections.namedtuple) from each row of the DataFrame.\n",
    "- Provided the DataFrame's column labels are valid Python identifiers (no spaces or special characters, must start with a letter of the alphabet), we can convert the tuple to a Python dictionary by calling its `_asdict()` method.\n",
    "- Finally, we can use Python's `str.format()` [method](https://docs.python.org/3/library/stdtypes.html#str.format) to substitute the placeholders in the URL with the appropriate values from each row. `str.format` accepts optional keyword arguments and uses them to fill any matching placeholder keys (the parts of the string between curly braces). - By passing to `str.format` our row-dictionary with the double-asterisk prefix -- `url.format(**row_dict)` -- we can unpack it into keyword arguments. **Provided our column names for MMS, Holdings, and Item ID match the keys in the URL string**, `str.format` will substitute those keys for the values we need.\n",
    "- `str.format` will ignore any keyword arguments that don't match the string, so it doesn't matter that our row-dictionary contains more columns than there are keys in the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_urls(url_str, df):\n",
    "    for row in df.itertuples(index=False):\n",
    "        yield url_str.format(**row._asdict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/9922645213604107/holdings/22401585210004107/items/23401585190004107',\n",
       " 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/9925377663604107/holdings/22401724220004107/items/23401724200004107',\n",
       " 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/9923212873604107/holdings/22401782970004107/items/23401782910004107',\n",
       " 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/9923212873604107/holdings/22401782970004107/items/23401782920004107',\n",
       " 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/9923212873604107/holdings/22401782970004107/items/23401782930004107',\n",
       " 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/9923212853604107/holdings/22401801900004107/items/23401801880004107',\n",
       " 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/9923212833604107/holdings/22401816810004107/items/23401816790004107',\n",
       " 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/9931940353604107/holdings/22401998400004107/items/23401998390004107',\n",
       " 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/9923243833604107/holdings/22402257820004107/items/23402257770004107',\n",
       " 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/9922685973604107/holdings/22402259240004107/items/23402259220004107',\n",
       " 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/9956771403604107/holdings/22402613840004107/items/23402613830004107',\n",
       " 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/9937457383604107/holdings/22402682130004107/items/23402682110004107',\n",
       " 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/9968854233604107/holdings/22402898910004107/items/23402898900004107',\n",
       " 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/99152110043604107/holdings/22402961520004107/items/23402961510004107',\n",
       " 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/9921658653604107/holdings/22403275480004107/items/23403275460004107',\n",
       " 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/9923857543604107/holdings/22403373730004107/items/23403373710004107',\n",
       " 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/99179891253604107/holdings/22403506380004107/items/23403506370004107',\n",
       " 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/9923851583604107/holdings/22403553370004107/items/23403553350004107',\n",
       " 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/9938872713604107/holdings/22403724770004107/items/23403724760004107',\n",
       " 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/9941236593604107/holdings/22404214140004107/items/23404214110004107',\n",
       " 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/9932273753604107/holdings/22404355210004107/items/23404355200004107',\n",
       " 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/9923472093604107/holdings/22404523290004107/items/23404523280004107',\n",
       " 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/9924596993604107/holdings/22404744340004107/items/23404744250004107',\n",
       " 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/9922969503604107/holdings/22404848750004107/items/23404848730004107',\n",
       " 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/9930496963604107/holdings/22405252030004107/items/23405252020004107',\n",
       " 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/9923651703604107/holdings/22405540490004107/items/23405540450004107',\n",
       " 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/9922122863604107/holdings/22405566840004107/items/23405566820004107',\n",
       " 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/9923042363604107/holdings/22405813830004107/items/23405813800004107',\n",
       " 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/99139422083604107/holdings/22405903140004107/items/23405903130004107',\n",
       " 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/9927343283604107/holdings/22406116240004107/items/23406116230004107',\n",
       " 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/9922229323604107/holdings/22406262250004107/items/23406262230004107',\n",
       " 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/9936965263604107/holdings/22406300460004107/items/23406300440004107',\n",
       " 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/9936966043604107/holdings/22406310550004107/items/23406310540004107',\n",
       " 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/99146228453604107/holdings/22406492380004107/items/23406492370004107',\n",
       " 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/9927473753604107/holdings/22406647770004107/items/23406647760004107',\n",
       " 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/9922140893604107/holdings/22406804240004107/items/23406804220004107',\n",
       " 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/9922140323604107/holdings/22406838200004107/items/23406838180004107',\n",
       " 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/9934513083604107/holdings/22406844970004107/items/23406844960004107',\n",
       " 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/9934510073604107/holdings/22406845890004107/items/23406845880004107',\n",
       " 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/9976348223604107/holdings/22406933660004107/items/23406933650004107',\n",
       " 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/9961121563604107/holdings/22407049920004107/items/23407049890004107',\n",
       " 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/9921932003604107/holdings/22407603030004107/items/23407603010004107',\n",
       " 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/9921858753604107/holdings/22407699690004107/items/23407699670004107',\n",
       " 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/9921852723604107/holdings/22407743690004107/items/23407743670004107',\n",
       " 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/9924502993604107/holdings/22407813850004107/items/23407813840004107',\n",
       " 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/9938004353604107/holdings/22407849160004107/items/23407849130004107',\n",
       " 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/9938005073604107/holdings/22407858720004107/items/23407858710004107',\n",
       " 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/9921853823604107/holdings/22407872740004107/items/23407872690004107',\n",
       " 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/9922237243604107/holdings/22407883020004107/items/23407883000004107',\n",
       " 'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/9938003223604107/holdings/22407919160004107/items/23407919140004107']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[url for url in format_urls(config['get_item_url'], art_books.iloc[:50])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need a header that contains our API key and one that instructs the API to return JSON. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'Authorization': f'apikey {config[\"api_key\"]}',\n",
    "          'Accept': 'application/json'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Putting it all together\n",
    "\n",
    "Finally, we make an `async` coroutine to create our concurrent requests. \n",
    "\n",
    "This coroutine accepts the following arguments:\n",
    "- A `DataFrame` (called `data`) where each row should contain a set of identifiers we want to pass to the Bibs API.\n",
    "- A Python dictionary containing the API headers (`headers`).\n",
    "- A complete URL for an API endpoint, suitable for formatting with the identifiers in our dataset.\n",
    "\n",
    "\n",
    "It does the following:\n",
    "- Creates an instance of the `asyncio_throttle.Throttler` class with the specified rate limit.\n",
    "- Creates an `aiohttp.ClientSession` instance via context manager.\n",
    "- Initializes a list of `get_item` coroutines with the formatted URLs.\n",
    "- Accumulates the results from those coroutines via `asyncio.gather`.\n",
    "- Returns the results.\n",
    "\n",
    "\n",
    "This is the coroutine we will pass to `asyncio.run` in order to kick off the event loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def make_requests(data, headers, base_url):\n",
    "    throttler = Throttler(rate_limit=25)\n",
    "    async with aiohttp.ClientSession() as client:\n",
    "        awaitables = [get_item(client=client,\n",
    "                               throttler=throttler, \n",
    "                               headers=headers,\n",
    "                                url=url) for url in format_urls(base_url, data)]\n",
    "        results = await asyncio.gather(*awaitables)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can launch our concurrent requests as follows. (If running this outside of a Jupyter notebook, you will need to write (assuming you're using Python 3.7+):\n",
    "```\n",
    "results = asyncio.run(make_requests(art_books, headers, config['get_item_url'])\n",
    "```\n",
    "The syntax for Python 3.5 and 3.6 is a little different. It should be\n",
    "```\n",
    "loop = asyncio.get_event_loop()\n",
    "results = loop.run_until_complete(make_requests(art_books, headers, config['get_item_url'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = await make_requests(art_books, headers, config['get_item_url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`results` should be a list of objects returned by the API, along with any errors. It should equal the length of our original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(results) == len(art_books)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can identify errors by looking for any objects within results that have the `error` key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{\"errorsExist\":true,\"errorList\":{\"error\":[{\"errorCode\":\"401683\",\"errorMessage\":\"No Item found for mmsId 9927473753604107, holdings id 22406647770004107 and item id 23406647760004107.\",\"trackingId\":\"E01-2309145237-4ZFZJ-AWAE392162647\"}]},\"result\":null}',\n",
       " '{\"errorsExist\":true,\"errorList\":{\"error\":[{\"errorCode\":\"401683\",\"errorMessage\":\"No Item found for mmsId 9924212553604107, holdings id 22408788330004107 and item id 23408788310004107.\",\"trackingId\":\"E01-2309145313-KWZBF-AWAE582686539\"}]},\"result\":null}',\n",
       " '{\"errorsExist\":true,\"errorList\":{\"error\":[{\"errorCode\":\"401683\",\"errorMessage\":\"No Item found for mmsId 99139479343604107, holdings id 22425722010004107 and item id 23425721990004107.\",\"trackingId\":\"E01-2309145244-XEQYM-AWAE392162647\"}]},\"result\":null}',\n",
       " '{\"errorsExist\":true,\"errorList\":{\"error\":[{\"errorCode\":\"401683\",\"errorMessage\":\"No Item found for mmsId 99139476363604107, holdings id 22425753010004107 and item id 23425752980004107.\",\"trackingId\":\"E01-2309145244-TNBR3-AWAE392162647\"}]},\"result\":null}',\n",
       " '{\"errorsExist\":true,\"errorList\":{\"error\":[{\"errorCode\":\"401683\",\"errorMessage\":\"No Item found for mmsId 99139472863604107, holdings id 22425892780004107 and item id 23425892760004107.\",\"trackingId\":\"E01-2309145240-SADB2-AWAE392162647\"}]},\"result\":null}',\n",
       " '{\"errorsExist\":true,\"errorList\":{\"error\":[{\"errorCode\":\"401683\",\"errorMessage\":\"No Item found for mmsId 9965350103604107, holdings id 22444168550004107 and item id 23444168540004107.\",\"trackingId\":\"E01-2309145303-9EOJX-AWAE392162647\"}]},\"result\":null}',\n",
       " '{\"errorsExist\":true,\"errorList\":{\"error\":[{\"errorCode\":\"401683\",\"errorMessage\":\"No Item found for mmsId 9927889623604107, holdings id 22449730180004107 and item id 23449730140004107.\",\"trackingId\":\"E01-2309145240-URKXY-AWAE392162647\"}]},\"result\":null}',\n",
       " '{\"errorsExist\":true,\"errorList\":{\"error\":[{\"errorCode\":\"401683\",\"errorMessage\":\"No Item found for mmsId 9968042113604107, holdings id 22456806670004107 and item id 23456806660004107.\",\"trackingId\":\"E01-2309145253-B14GH-AWAE392162647\"}]},\"result\":null}',\n",
       " '{\"errorsExist\":true,\"errorList\":{\"error\":[{\"errorCode\":\"401683\",\"errorMessage\":\"No Item found for mmsId 9927745933604107, holdings id 22466745610004107 and item id 23466745590004107.\",\"trackingId\":\"E01-2309145314-P8GPX-AWAE582686539\"}]},\"result\":null}',\n",
       " '{\"errorsExist\":true,\"errorList\":{\"error\":[{\"errorCode\":\"401683\",\"errorMessage\":\"No Item found for mmsId 99139489113604107, holdings id 22510577650004107 and item id 23510577620004107.\",\"trackingId\":\"E01-2309145243-0YJS0-AWAE392162647\"}]},\"result\":null}',\n",
       " '{\"errorsExist\":true,\"errorList\":{\"error\":[{\"errorCode\":\"401683\",\"errorMessage\":\"No Item found for mmsId 9927574373604107, holdings id 22527568950004107 and item id 23527568890004107.\",\"trackingId\":\"E01-2309145312-CK1XX-AWAE582686539\"}]},\"result\":null}']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[r['message'] for r in results if 'error' in r]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternately, we may want to mark the rows in our original list that we have successfully completed.\n",
    "\n",
    "First, we create a list of unique Item identifiers in our results set (filtering out any errors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = [r['response']['item_data']['pid'] for r in results if 'error' not in r]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can use `pandas` functionality to add a column with values based on a Boolean condition: whether the value in the `item_id` column is in our `items` list.\n",
    "\n",
    "**Note** that our `item_id` column was imported as an integer value, but `items` is a list a strings. So we need to do an explicit type cast in order for the test to work. `DataFrame['item_id'].astype(str)` converts the values in that column to strings.\n",
    "\n",
    "Then we can use the `.asin` method to check for membership in a list. This will return a list of `True`/`False` values aligned with the original column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-150-afa3759e0fa7>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  art_books['item_id'] = art_books['item_id'].astype(str)\n",
      "<ipython-input-150-afa3759e0fa7>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  art_books['completed'] = art_books['item_id'].isin(items)\n"
     ]
    }
   ],
   "source": [
    "art_books['item_id'] = art_books['item_id'].astype(str)\n",
    "art_books['completed'] = art_books['item_id'].isin(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that code produces a `SettingWithCopyWarning`, it's safe to ignore it in this case. We can check to make sure that our flag works by comparing the subset of values in the `completed` column that are `False` with the list of error messages we received."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(art_books.loc[art_books.completed == False]) == len([r['message'] for r in results if 'error' in r])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we can save our flagged dataset back to the disk as CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_books.to_csv('art_books_completed.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
